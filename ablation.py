import torch
import os
import json
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from config import Config
from train import Trainer
import numpy as np


class AblationConfig(Config):
    """æ¶ˆèå®éªŒé…ç½®"""
    def __init__(self, n_layers, n_heads, exp_name):
        super().__init__()
        self.n_layers = n_layers
        self.n_heads = n_heads
        self.exp_name = exp_name
        
        # å‡å°‘è®­ç»ƒè½®æ•°ä»¥åŠ å¿«å®éªŒé€Ÿåº¦
        self.max_epochs = 5  # 20â†’15 epochs
        
        # ç¡®ä¿ d_model èƒ½è¢« n_heads æ•´é™¤
        assert self.d_model % n_heads == 0, f"d_model ({self.d_model}) must be divisible by n_heads ({n_heads})"
        
    def __repr__(self):
        return f"""
Ablation Experiment: {self.exp_name}
  Layers: {self.n_layers}, Heads: {self.n_heads}
  d_model: {self.d_model}, batch_size: {self.batch_size}
  Epochs: {self.max_epochs}
"""


class AblationStudy:
    """æ¶ˆèå®éªŒç®¡ç†å™¨"""
    def __init__(self, base_config, save_dir='ablation_results'):
        self.base_config = base_config
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
        
        # å®éªŒé…ç½®
        self.experiments = self.design_experiments()
        self.results = []
        
    def design_experiments(self):
        """è®¾è®¡æ¶ˆèå®éªŒ
        
        å®éªŒè®¾è®¡ï¼š
        1. å›ºå®šå¤´æ•°ï¼Œå˜åŒ–å±‚æ•°ï¼šéªŒè¯æ·±åº¦çš„å½±å“
        2. å›ºå®šå±‚æ•°ï¼Œå˜åŒ–å¤´æ•°ï¼šéªŒè¯å¤šå¤´æ³¨æ„åŠ›çš„å½±å“
        """
        experiments = []
        
        # åŸºå‡†å®éªŒ
        experiments.append({
            'name': 'baseline',
            'n_layers': 8,
            'n_heads': 4,
            'description': 'Baseline (8 layers, 4 heads)'
        })
        
        # å®éªŒç»„1ï¼šå›ºå®šå¤´æ•°(4)ï¼Œå˜åŒ–å±‚æ•°
        print("\n" + "="*60)
        print("Experiment Group 1: Varying Layers (Fixed Heads=4)")
        print("="*60)
        for n_layers in [4, 6, 10, 12]:
            experiments.append({
                'name': f'layers_{n_layers}_heads_4',
                'n_layers': n_layers,
                'n_heads': 4,
                'description': f'{n_layers} layers, 4 heads'
            })
            print(f"  - {n_layers} layers, 4 heads")
        
        # å®éªŒç»„2ï¼šå›ºå®šå±‚æ•°(8)ï¼Œå˜åŒ–å¤´æ•°
        print("\n" + "="*60)
        print("Experiment Group 2: Varying Heads (Fixed Layers=8)")
        print("="*60)
        for n_heads in [2, 8, 16]:
            # ç¡®ä¿èƒ½æ•´é™¤
            if 512 % n_heads == 0:
                experiments.append({
                    'name': f'layers_8_heads_{n_heads}',
                    'n_layers': 8,
                    'n_heads': n_heads,
                    'description': f'8 layers, {n_heads} heads'
                })
                print(f"  - 8 layers, {n_heads} heads")
        
        print(f"\nTotal: {len(experiments)} experiments")
        print("="*60 + "\n")
        
        return experiments
    
    def run_experiment(self, exp_config):
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        print("\n" + "="*70)
        print(f"ğŸ”¬ Running: {exp_config['description']}")
        print("="*70)
        
        # åˆ›å»ºé…ç½®
        config = AblationConfig(
            n_layers=exp_config['n_layers'],
            n_heads=exp_config['n_heads'],
            exp_name=exp_config['name']
        )
        print(config)
        
        # è®­ç»ƒ
        trainer = Trainer(config)
        trainer.train()
        
        # æ”¶é›†ç»“æœ
        result = {
            'name': exp_config['name'],
            'description': exp_config['description'],
            'n_layers': exp_config['n_layers'],
            'n_heads': exp_config['n_heads'],
            'n_params': trainer.model.count_parameters(),
            'train_losses': trainer.train_losses,
            'valid_losses': trainer.valid_losses,
            'train_ppls': trainer.train_ppls,
            'valid_ppls': trainer.valid_ppls,
            'best_valid_loss': min(trainer.valid_losses),
            'best_valid_ppl': min(trainer.valid_ppls),
            'final_valid_loss': trainer.valid_losses[-1],
            'final_valid_ppl': trainer.valid_ppls[-1]
        }
        
        # ä¿å­˜ç»“æœ
        self.results.append(result)
        self.save_results()
        
        # æ¸…ç†æ˜¾å­˜
        del trainer
        torch.cuda.empty_cache()
        
        return result
    
    def run_all(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print("\n" + "ğŸš€"*35)
        print(f"Starting Ablation Study: {len(self.experiments)} experiments")
        print("ğŸš€"*35 + "\n")
        
        for i, exp in enumerate(self.experiments, 1):
            print(f"\n{'='*70}")
            print(f"Progress: [{i}/{len(self.experiments)}]")
            print(f"{'='*70}")
            
            try:
                self.run_experiment(exp)
            except Exception as e:
                print(f"âŒ Experiment {exp['name']} failed: {e}")
                continue
        
        print("\n" + "âœ…"*35)
        print("Ablation Study Completed!")
        print("âœ…"*35 + "\n")
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self.generate_report()
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        results_file = os.path.join(self.save_dir, 'results.json')
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_results = []
        for r in self.results:
            result_copy = r.copy()
            # å°†numpyæ•°ç»„è½¬ä¸ºåˆ—è¡¨
            for key in ['train_losses', 'valid_losses', 'train_ppls', 'valid_ppls']:
                if key in result_copy:
                    result_copy[key] = [float(x) for x in result_copy[key]]
            serializable_results.append(result_copy)
        
        with open(results_file, 'w') as f:
            json.dump(serializable_results, f, indent=2)
        
        print(f"Results saved to {results_file}")
    
    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–"""
        print("\n" + "="*70)
        print("ğŸ“Š Generating Analysis Report...")
        print("="*70 + "\n")
        
        # 1. åˆ›å»ºç»“æœè¡¨æ ¼
        self.create_results_table()
        
        # 2. ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¯¹æ¯”
        self.plot_training_curves()
        
        # 3. ç»˜åˆ¶å±‚æ•°å½±å“åˆ†æ
        self.plot_layers_analysis()
        
        # 4. ç»˜åˆ¶å¤´æ•°å½±å“åˆ†æ
        self.plot_heads_analysis()
        
        # 5. å‚æ•°é‡vsæ€§èƒ½åˆ†æ
        self.plot_params_vs_performance()
        
        print("\nâœ… Report generated successfully!")
        print(f"   All results saved to: {self.save_dir}/")
    
    def create_results_table(self):
        """åˆ›å»ºç»“æœå¯¹æ¯”è¡¨"""
        print("Creating results table...")
        
        # å‡†å¤‡æ•°æ®
        data = []
        for r in self.results:
            data.append({
                'Experiment': r['description'],
                'Layers': r['n_layers'],
                'Heads': r['n_heads'],
                'Parameters (M)': f"{r['n_params']/1e6:.2f}",
                'Best Valid Loss': f"{r['best_valid_loss']:.4f}",
                'Best Valid PPL': f"{r['best_valid_ppl']:.2f}",
                'Final Valid Loss': f"{r['final_valid_loss']:.4f}",
                'Final Valid PPL': f"{r['final_valid_ppl']:.2f}"
            })
        
        df = pd.DataFrame(data)
        
        # ä¿å­˜ä¸ºCSV
        csv_path = os.path.join(self.save_dir, 'results_table.csv')
        df.to_csv(csv_path, index=False)
        
        # æ‰“å°è¡¨æ ¼
        print("\n" + "="*100)
        print("ABLATION STUDY RESULTS")
        print("="*100)
        print(df.to_string(index=False))
        print("="*100 + "\n")
        
        # ä¿å­˜ä¸ºæ–‡æœ¬
        txt_path = os.path.join(self.save_dir, 'results_table.txt')
        with open(txt_path, 'w') as f:
            f.write("="*100 + "\n")
            f.write("ABLATION STUDY RESULTS\n")
            f.write("="*100 + "\n")
            f.write(df.to_string(index=False))
            f.write("\n" + "="*100 + "\n")
    
    def plot_training_curves(self):
        """ç»˜åˆ¶æ‰€æœ‰å®éªŒçš„è®­ç»ƒæ›²çº¿"""
        print("Plotting training curves...")
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # é¢œè‰²æ˜ å°„
        colors = plt.cm.tab10(np.linspace(0, 1, len(self.results)))
        
        for idx, r in enumerate(self.results):
            epochs = range(1, len(r['valid_losses']) + 1)
            label = r['description']
            color = colors[idx]
            
            # Train Loss
            axes[0, 0].plot(epochs, r['train_losses'], label=label, 
                           color=color, linewidth=2, alpha=0.8)
            
            # Valid Loss
            axes[0, 1].plot(epochs, r['valid_losses'], label=label, 
                           color=color, linewidth=2, alpha=0.8)
            
            # Train PPL
            axes[1, 0].plot(epochs, r['train_ppls'], label=label, 
                           color=color, linewidth=2, alpha=0.8)
            
            # Valid PPL
            axes[1, 1].plot(epochs, r['valid_ppls'], label=label, 
                           color=color, linewidth=2, alpha=0.8)
        
        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        axes[0, 0].set_title('Training Loss', fontsize=14, fontweight='bold')
        axes[0, 1].set_title('Validation Loss', fontsize=14, fontweight='bold')
        axes[1, 0].set_title('Training Perplexity', fontsize=14, fontweight='bold')
        axes[1, 1].set_title('Validation Perplexity', fontsize=14, fontweight='bold')
        
        for ax in axes.flat:
            ax.set_xlabel('Epoch', fontsize=12)
            ax.grid(True, alpha=0.3)
            ax.legend(fontsize=9, loc='best')
        
        axes[0, 0].set_ylabel('Loss', fontsize=12)
        axes[0, 1].set_ylabel('Loss', fontsize=12)
        axes[1, 0].set_ylabel('Perplexity', fontsize=12)
        axes[1, 1].set_ylabel('Perplexity', fontsize=12)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_dir, 'all_training_curves.png'), 
                   dpi=150, bbox_inches='tight')
        plt.close()
    
    def plot_layers_analysis(self):
        """åˆ†æå±‚æ•°çš„å½±å“ï¼ˆå›ºå®šå¤´æ•°=4ï¼‰"""
        print("Plotting layers analysis...")
        
        # ç­›é€‰å›ºå®šå¤´æ•°çš„å®éªŒ
        layer_results = [r for r in self.results if r['n_heads'] == 4]
        layer_results.sort(key=lambda x: x['n_layers'])
        
        if len(layer_results) < 2:
            return
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        
        layers = [r['n_layers'] for r in layer_results]
        best_ppls = [r['best_valid_ppl'] for r in layer_results]
        final_ppls = [r['final_valid_ppl'] for r in layer_results]
        params = [r['n_params']/1e6 for r in layer_results]
        
        # Best Valid PPL vs Layers
        axes[0].plot(layers, best_ppls, 'o-', linewidth=2, markersize=10, color='#2E86AB')
        axes[0].set_xlabel('Number of Layers', fontsize=12)
        axes[0].set_ylabel('Best Valid Perplexity', fontsize=12)
        axes[0].set_title('Best PPL vs Layers (Heads=4)', fontsize=14, fontweight='bold')
        axes[0].grid(True, alpha=0.3)
        
        # Final Valid PPL vs Layers
        axes[1].plot(layers, final_ppls, 's-', linewidth=2, markersize=10, color='#A23B72')
        axes[1].set_xlabel('Number of Layers', fontsize=12)
        axes[1].set_ylabel('Final Valid Perplexity', fontsize=12)
        axes[1].set_title('Final PPL vs Layers (Heads=4)', fontsize=14, fontweight='bold')
        axes[1].grid(True, alpha=0.3)
        
        # Parameters vs Layers
        axes[2].plot(layers, params, 'd-', linewidth=2, markersize=10, color='#F18F01')
        axes[2].set_xlabel('Number of Layers', fontsize=12)
        axes[2].set_ylabel('Parameters (M)', fontsize=12)
        axes[2].set_title('Model Size vs Layers', fontsize=14, fontweight='bold')
        axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_dir, 'layers_analysis.png'), 
                   dpi=150, bbox_inches='tight')
        plt.close()
    
    def plot_heads_analysis(self):
        """åˆ†æå¤´æ•°çš„å½±å“ï¼ˆå›ºå®šå±‚æ•°=8ï¼‰"""
        print("Plotting heads analysis...")
        
        # ç­›é€‰å›ºå®šå±‚æ•°çš„å®éªŒ
        head_results = [r for r in self.results if r['n_layers'] == 8]
        head_results.sort(key=lambda x: x['n_heads'])
        
        if len(head_results) < 2:
            return
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        heads = [r['n_heads'] for r in head_results]
        best_ppls = [r['best_valid_ppl'] for r in head_results]
        final_ppls = [r['final_valid_ppl'] for r in head_results]
        
        # Best Valid PPL vs Heads
        axes[0].plot(heads, best_ppls, 'o-', linewidth=2, markersize=10, color='#06A77D')
        axes[0].set_xlabel('Number of Heads', fontsize=12)
        axes[0].set_ylabel('Best Valid Perplexity', fontsize=12)
        axes[0].set_title('Best PPL vs Heads (Layers=8)', fontsize=14, fontweight='bold')
        axes[0].set_xscale('log', base=2)
        axes[0].grid(True, alpha=0.3)
        
        # Final Valid PPL vs Heads
        axes[1].plot(heads, final_ppls, 's-', linewidth=2, markersize=10, color='#D62246')
        axes[1].set_xlabel('Number of Heads', fontsize=12)
        axes[1].set_ylabel('Final Valid Perplexity', fontsize=12)
        axes[1].set_title('Final PPL vs Heads (Layers=8)', fontsize=14, fontweight='bold')
        axes[1].set_xscale('log', base=2)
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_dir, 'heads_analysis.png'), 
                   dpi=150, bbox_inches='tight')
        plt.close()
    
    def plot_params_vs_performance(self):
        """ç»˜åˆ¶å‚æ•°é‡vsæ€§èƒ½çš„å…³ç³»"""
        print("Plotting parameters vs performance...")
        
        fig, ax = plt.subplots(1, 1, figsize=(10, 7))
        
        params = [r['n_params']/1e6 for r in self.results]
        best_ppls = [r['best_valid_ppl'] for r in self.results]
        labels = [r['description'] for r in self.results]
        
        # æ•£ç‚¹å›¾
        scatter = ax.scatter(params, best_ppls, s=200, alpha=0.6, 
                            c=range(len(self.results)), cmap='viridis')
        
        # æ·»åŠ æ ‡ç­¾
        for i, label in enumerate(labels):
            ax.annotate(label, (params[i], best_ppls[i]), 
                       fontsize=9, ha='right', va='bottom',
                       bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))
        
        ax.set_xlabel('Parameters (M)', fontsize=12)
        ax.set_ylabel('Best Valid Perplexity', fontsize=12)
        ax.set_title('Model Size vs Performance', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_dir, 'params_vs_performance.png'), 
                   dpi=150, bbox_inches='tight')
        plt.close()


def main():
    """è¿è¡Œæ¶ˆèå®éªŒ"""
    # åˆ›å»ºåŸºç¡€é…ç½®
    base_config = Config()
    
    # åˆ›å»ºæ¶ˆèå®éªŒ
    ablation = AblationStudy(base_config)
    
    # è¿è¡Œæ‰€æœ‰å®éªŒ
    ablation.run_all()
    
    print("\n" + "ğŸ‰"*35)
    print(f"All results saved to: {ablation.save_dir}/")
    print("ğŸ‰"*35 + "\n")


if __name__ == '__main__':
    main()